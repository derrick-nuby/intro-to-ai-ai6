{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/derrick-nuby/intro-to-ai-ai6/blob/hw1-answers/assignments/hw01_style_transfer/hw01_answer.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jH7vqEUuxBb4"
   },
   "source": [
    "# Style transfer using a Linear Transformation\n",
    "\n",
    "Here we have three pieces of audio. The first two are `Synth.wav` (audio $\\mathbf{A}$) and `Piano.wav` (audio $\\mathbf{B}$), which are recordings of a chromatic scale in a single octave played by a synthesizer and a piano respectively. The third piece of audio is the intro melody of “Blinding Lights” (audio $\\mathbf{C}$) by The Weeknd, played with the same synth tone used to generate `Synth.wav`.\n",
    "\n",
    "All audio files are in the `hw01_style_transfer/data` folder.\n",
    "\n",
    "From these files, you can obtain the spectrogram $\\mathbf{M}_A$, $\\mathbf{M}_B$ and $\\mathbf{M}_C$ . Your objective is to find the spectrogram of the piano version of the song “Blinding Lights” ($\\mathbf{M}_D$).\n",
    "\n",
    "In this problem, we assume that style can be transferred using a linear transformation. Formally, we need\n",
    "to find the matrix $\\mathbf{T}$ such that:\n",
    "\n",
    "$$\n",
    "\\mathbf{TM}_A ≈ \\mathbf{M}_B\n",
    "$$\n",
    "\n",
    "1. Write your code to determine matrix $\\mathbf{T}$.\n",
    "\n",
    "2. Our model assumes that $\\mathbf{T}$ can transfer style from synthesizer music to piano music. Applying $\\mathbf{T}$ on $\\mathbf{M}_C$ should give us a estimation of “Blinding Lights” played by Piano, getting an estimation of $\\mathbf{M}_D$. Using this matrix and phase matrix of $\\mathbf{C}$, synthesize an audio signal.\n",
    "\n",
    "    Submit your sythensized audio named as $\\mathbf{problem3.wav}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_a9WPA30fmJr"
   },
   "outputs": [],
   "source": [
    "# mounts your google drive to help you access files stored on your drive directly like you would on you local machine\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"/content/gdrive\")\n",
    "# %cd gdrive/MyDrive/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QI1EJkC4bRr"
   },
   "source": [
    "## Solution\n",
    "\n",
    "You need to compute the spectrogram of the music file. First, read and load the audio file at its correct sample rate (44100 in our case).\n",
    "\n",
    "If you are using Python, you can use [Librosa](https://librosa.org/doc/latest/index.html) to load the wav file as follows (we also recommend using the numpy package for matrix operations below if you use python):\n",
    "\n",
    "```python\n",
    "import librosa\n",
    "audio, sr = librosa.load(filename, sr = None) # sr = None means the audio will be loaded with its original sr - sample rate\n",
    "assert sr = 44100 # we want to make sure the computed sr from the music file is what we expect - 44100 Hz\n",
    "```\n",
    "\n",
    "Next, we can compute the complex Short-Time Fourier Transform (STFT) of the signal and its magnitude spectrogram. Use `2048` sample windows, which correspond to 64 ms analysis windows; overlap/hop length of `256` samples to 64 frames by second of signal. Different toolboxes should provide similar spectrograms. If\n",
    "you are using the Python Librosa library, you can use the following command:\n",
    "\n",
    "```python\n",
    "spectrogram = librosa.stft(audio, n_fft=2048, hop_length=256, center=False, win_length=2048)\n",
    "M = abs(spectrogram)\n",
    "phase = spectrogram/(M + 2.2204e-16)\n",
    "```\n",
    "\n",
    "In this case, $\\mathbf{M}$ represents the music file and should be a matrix, where the rows correspond to the frequencies and the columns to time. For visualizing the spectrogram, see the documentation online for `librosa.display.specshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJYpJk-1jlZX"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJmr5hQPF5DZ"
   },
   "source": [
    "### Computing $\\mathbf{M}_A$, $\\mathbf{M}_B$, $\\mathbf{M}_C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riLIQ48aF3yS"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# Load audio files\n",
    "audio_A, sr = librosa.load('data/Synth.wav', sr=None)\n",
    "audio_B, sr = librosa.load('data/Piano.wav', sr=None)\n",
    "audio_C, sr = librosa.load('data/Blinding_Lights_synth.wav', sr=None)\n",
    "assert sr == 44100  # Verify sample rate\n",
    "\n",
    "# Compute STFT for each audio\n",
    "spectrogram_A = librosa.stft(audio_A, n_fft=2048, hop_length=256, center=False, win_length=2048)\n",
    "spectrogram_B = librosa.stft(audio_B, n_fft=2048, hop_length=256, center=False, win_length=2048)\n",
    "spectrogram_C = librosa.stft(audio_C, n_fft=2048, hop_length=256, center=False, win_length=2048)\n",
    "\n",
    "# Compute magnitude and phase\n",
    "MA = np.abs(spectrogram_A)\n",
    "phase_A = spectrogram_A / (MA + 2.2204e-16)  # Avoid division by zero\n",
    "\n",
    "MB = np.abs(spectrogram_B)\n",
    "phase_B = spectrogram_B / (MB + 2.2204e-16)\n",
    "\n",
    "MC = np.abs(spectrogram_C)\n",
    "phase_C = spectrogram_C / (MC + 2.2204e-16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fr287zw9Snr"
   },
   "source": [
    "### Learning $\\mathbf{T}$\n",
    "\n",
    "We were given that:\n",
    "\n",
    "$$\n",
    "TM_{A} ≈ M_{B}\n",
    "$$\n",
    "\n",
    "From basic math, we know that:\n",
    "\n",
    "$$\n",
    "T = \\frac{M_{B}}{M_{A}} = M_{B} * \\frac{1}{M_{A}}\n",
    "$$\n",
    "\n",
    "$\\frac{1}{M_{A}}$ is known as the inverse of $\\mathbf{A}$, which can also be written as $M_{A}^{-1}.$ So our final formula will be:\n",
    "$$\n",
    "T = M_{B} * pinv(M_{A})\n",
    "$$\n",
    "\n",
    "where $pinv$ meanse the [pseudo-inverse](https://numpy.org/doc/stable/reference/generated/numpy.linalg.pinv.html) of a matrix. We use the pseudo-inverse ($pinv$) because **$M_{A}$ is not a square matrix**\n",
    "\n",
    "**Step 1**: Compute $\\mathbf{T}$\n",
    "\n",
    "Hint: use [matrix multiplication](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html) not element-wise multiplcation for your multipliction operation to avoid broadcast error. **Try and understand why**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfhTLk8u5yl8"
   },
   "outputs": [],
   "source": [
    "# Compute T using matrix multiplication and pseudo-inverse\n",
    "T = np.matmul(MB, np.linalg.pinv(MA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XU_q-4AH-nom"
   },
   "source": [
    "### Computing error\n",
    "\n",
    "We also would like to know how well the $\\mathbf{T}$ we got represents a good style transfer from synthesizer music to piano music. We can do ths by computing the error. In this case, we would use the [frobenius norm](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html).\n",
    "\n",
    "**Step 2:** Compute error $∥TM_{A} − M_{B} ∥^{2}_{F}$\n",
    "\n",
    "Hint: use [matrix multiplication](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html) not element-wise multiplcation for your multipliction operation to avoid broadcast error. Try and understand why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXfZzSjr_gg_"
   },
   "outputs": [],
   "source": [
    "# Compute error using Frobenius norm\n",
    "error = np.linalg.norm(np.matmul(T, MA) - MB, ord='fro') ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KSQ3nazBcWf"
   },
   "source": [
    "### Finding $\\mathbf{M}_D$\n",
    "\n",
    "Our model assumes that $\\mathbf{T}$ can transfer style from synthesizer music to piano music. Applying $\\mathbf{T}$ on $\\mathbf{M}_C$ should give us an estimation of “Blinding Lights” played by Piano, getting an estimation of $\\mathbf{M}_D$.\n",
    "\n",
    "$$\n",
    "\\mathbf{M}_D = \\mathbf{T} * \\mathbf{M}_C\n",
    "$$\n",
    "\n",
    "**Step 3:** Compute $\\mathbf{M}_D$\n",
    "\n",
    "Hint: use [matrix multiplication](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html) not element-wise multiplcation for your multipliction operation to avoid broadcast error. **Try and understand why**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSGZtC-BJbcU"
   },
   "outputs": [],
   "source": [
    "# Compute MD using matrix multiplication\n",
    "MD = np.matmul(T, MC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEmTN99f66OH"
   },
   "source": [
    "### Recover $\\mathbf{M}_D$ signal\n",
    "\n",
    "To recover the signal from the constructed spectrogram $\\mathbf{M}_D$ we need to use the `phase` matrix we computed earlier from the original signal. Combine both and compute the Inverse-STFT to obtain a vector and then write them into a wav file. To compute the STFT and then write the wav file you can use the following python command:\n",
    "\n",
    "```python\n",
    "# Latest Librosa doesn't have an audio write function. Use PySoundFile instead.\n",
    "import soundfile as sf\n",
    "signal = librosa.istft(spectrogram * phase, hop_length=256, center=False, win_length=2048)\n",
    "sf.write(\"problem3.wav\", spectrogram, 44100) # here we use the original sr which is 44100 Hz\n",
    "```\n",
    "\n",
    "**Step 4:** Using the matrix, $\\mathbf{M}_D$ and **phase matrix of $\\mathbf{C}$**, synthesize an audio signal.\n",
    "\n",
    "Hint: Here use **element-wise multiplication**. **Try and understand why**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdo05bpI7O2T"
   },
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "# Recover the signal from MD using phase_C\n",
    "MD_spectrogram = MD * phase_C\n",
    "MD_signal = librosa.istft(MD_spectrogram, hop_length=256, center=False, win_length=2048)\n",
    "\n",
    "# Save the signal to problem3.wav\n",
    "sf.write(\"problem3.wav\", MD_signal, 44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqJ6WFcjL0jB"
   },
   "source": [
    "### Bonus: Check your reconstructed signal music:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 61
    },
    "id": "3ixz_ed3L-b8",
    "outputId": "8de41ed0-f87d-45a5-e554-b5e94e0469b3"
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio('problem3.wav') # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgFRHz6PgPPD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
